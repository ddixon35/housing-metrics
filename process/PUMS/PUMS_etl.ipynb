{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import pyodbc\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = \"DRIVER={ODBC Driver 17 for SQL Server}; SERVER=AWS-PROD-SQL\\Sockeye; DATABASE=Elmer; trusted_connection=yes\"\n",
    "sql_conn = pyodbc.connect(conn_string)\n",
    "params = urllib.parse.quote_plus(conn_string)\n",
    "engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('..\\\\..\\\\data\\\\PUMS\\\\')\n",
    "year = 2019\n",
    "pums_csv_name_persons = 'psam_p53.csv'\n",
    "pums_csv_name_housing = 'hsam_p53.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pums_base_url = 'https://www2.census.gov/programs-surveys/acs/data/pums/{}/1-Year/'.format(str(year))\n",
    "pums_doc_url = 'https://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMS_Data_Dictionary_2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_zip = 'csv_pwa.zip'\n",
    "pums_person_url = pums_base_url + person_zip\n",
    "pums_person_file = data_dir / person_zip\n",
    "housing_zip = 'csv_hwa.zip'\n",
    "pums_housing_url = pums_base_url + housing_zip\n",
    "pums_housing_file = data_dir / housing_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get(pums_person_url)\n",
    "with open(pums_person_file, 'wb') as f:\n",
    "    f.write(r.content)\n",
    "with zipfile.ZipFile(pums_person_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get(pums_housing_url)\n",
    "with open(pums_housing_file, 'wb') as f:\n",
    "    f.write(r.content)\n",
    "with zipfile.ZipFile(pums_housing_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_cols = ['dd_type','colname','datatype','length', 'col_e','col_f','col_g']\n",
    "df_dd = pd.read_csv(pums_doc_url, header=None, names=data_dict_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_colnames = df_dd[df_dd.dd_type =='NAME']\n",
    "df_vals = df_dd[df_dd.dd_type == 'VAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_csv_path = data_dir / 'psam_p53.csv'\n",
    "df_persons = pd.read_csv(person_csv_path, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_csv_path = data_dir / 'psam_h53.csv'\n",
    "df_housing = pd.read_csv(housing_csv_path, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_df(pums_col):\n",
    "    df = df_vals[df_vals.colname == pums_col][['colname','datatype','length','col_e','col_f','col_g']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type(pums_col):\n",
    "    data_type = df_colnames[df_colnames.colname == pums_col].datatype.unique()[0]\n",
    "    range_cols = df_vals[df_vals.col_e != df_vals.col_f].colname.unique()\n",
    "    if data_type == 'C' and pums_col not in range_cols:\n",
    "        returned_data_type = 'char_lookup'\n",
    "    else:\n",
    "        returned_data_type = data_type\n",
    "    return returned_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_char_column(pums_df, col_name):\n",
    "    df_temp = lookup_df(col_name)\n",
    "    #df_temp = df_housing.merge(df_access, how='left', left_on='ACCESS', right_on='col_e')\n",
    "    pums_df[col_name] = pums_df.merge(df_temp, how='left', left_on=col_name, right_on='col_e')[['col_g']]\n",
    "    return pums_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_columns(pums_df):\n",
    "    working_df = pums_df.copy(deep=True)\n",
    "    for col in working_df.columns:\n",
    "        col_type = data_type(col)\n",
    "        if col_type == 'char_lookup':\n",
    "            working_df_df = decode_char_column(working_df, col)  \n",
    "    return working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_decoded = decode_columns(df_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_decoded = decode_columns(df_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def castable(df, col_name, dtype):\n",
    "    try:\n",
    "        df[col_name].astype(dtype)\n",
    "        return True\n",
    "    \n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stage_table_col_types(pums_df):\n",
    "    col_types = {}\n",
    "    for c in pums_df.columns:\n",
    "        if castable(pums_df, c, np.int16):\n",
    "            dtype = np.int16\n",
    "        elif castable(pums_df, c, np.int32):\n",
    "            dtype = np.int32\n",
    "        elif castable(pums_df, c, np.int64):\n",
    "            dtype = np.int64\n",
    "        elif castable(pums_df, c, np.float64 ):\n",
    "            dtype = np.float64\n",
    "        else:\n",
    "            dtype = object\n",
    "        col_types[c] = dtype\n",
    "    return col_types  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recast_coltypes(df):\n",
    "    new_dtypes = get_stage_table_col_types(df)\n",
    "    for col in new_dtypes.keys():\n",
    "        df[col] = df[col].astype(new_dtypes[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RT           object\n",
       "SERIALNO     object\n",
       "DIVISION     object\n",
       "SPORDER       int16\n",
       "PUMA          int16\n",
       "REGION       object\n",
       "ST           object\n",
       "ADJINC       object\n",
       "PWGTP         int16\n",
       "AGEP          int16\n",
       "CIT          object\n",
       "CITWP       float64\n",
       "COW          object\n",
       "DDRS         object\n",
       "DEAR         object\n",
       "DEYE         object\n",
       "DOUT         object\n",
       "DPHY         object\n",
       "DRAT         object\n",
       "DRATX        object\n",
       "DREM         object\n",
       "ENG          object\n",
       "FER          object\n",
       "GCL          object\n",
       "GCM          object\n",
       "GCR          object\n",
       "HIMRKS       object\n",
       "HINS1        object\n",
       "HINS2        object\n",
       "HINS3        object\n",
       "             ...   \n",
       "PWGTP51       int16\n",
       "PWGTP52       int16\n",
       "PWGTP53       int16\n",
       "PWGTP54       int16\n",
       "PWGTP55       int16\n",
       "PWGTP56       int16\n",
       "PWGTP57       int16\n",
       "PWGTP58       int16\n",
       "PWGTP59       int16\n",
       "PWGTP60       int16\n",
       "PWGTP61       int16\n",
       "PWGTP62       int16\n",
       "PWGTP63       int16\n",
       "PWGTP64       int16\n",
       "PWGTP65       int16\n",
       "PWGTP66       int16\n",
       "PWGTP67       int16\n",
       "PWGTP68       int16\n",
       "PWGTP69       int16\n",
       "PWGTP70       int16\n",
       "PWGTP71       int16\n",
       "PWGTP72       int16\n",
       "PWGTP73       int16\n",
       "PWGTP74       int16\n",
       "PWGTP75       int16\n",
       "PWGTP76       int16\n",
       "PWGTP77       int16\n",
       "PWGTP78       int16\n",
       "PWGTP79       int16\n",
       "PWGTP80       int16\n",
       "Length: 288, dtype: object"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_staging(df, table_name):\n",
    "    recast_coltypes(df)\n",
    "    df.to_sql(name=table_name, schema='stg', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_staging(df_persons_decoded, 'psam_p53_2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_staging(df_housing_decoded, 'psam_h53_2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsr = sql_conn.cursor()\n",
    "crsr.execute('exec census.merge_pums_persons_2019')\n",
    "sql_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'pums_persons_dd' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-36025de3260e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_colnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pums_persons_dd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'stg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2529\u001b[0m         sql.to_sql(self, name, con, schema=schema, if_exists=if_exists,\n\u001b[0;32m   2530\u001b[0m                    \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2531\u001b[1;33m                    dtype=dtype, method=method)\n\u001b[0m\u001b[0;32m   2532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2533\u001b[0m     def to_pickle(self, path, compression='infer',\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m    458\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[0;32m    459\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m                       chunksize=chunksize, dtype=dtype, method=method)\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   1171\u001b[0m                          \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m                          schema=schema, dtype=dtype)\n\u001b[1;32m-> 1173\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1174\u001b[0m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'fail'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 575\u001b[1;33m                     \"Table '{name}' already exists.\".format(name=self.name))\n\u001b[0m\u001b[0;32m    576\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Table 'pums_persons_dd' already exists."
     ]
    }
   ],
   "source": [
    "df_colnames.to_sql(name='pums_persons_dd', schema='stg', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsr = sql_conn.cursor()\n",
    "sql_statement = '''\n",
    "\twith dd as (\n",
    "\t\tselect distinct colname, col_e as col_definition\n",
    "\t\tfrom stg.pums_persons_dd\n",
    "\t)\n",
    "\tupdate meta.[columns]\n",
    "\tset [description] = dd.col_definition\n",
    "\tfrom meta.[columns] c\n",
    "\t\tjoin meta.[tables] t ON c.table_id = t.table_id\n",
    "\t\tjoin dd on c.[name] = dd.colname\n",
    "\twhere t.[name] = 'pums_persons_2019'\n",
    "'''\n",
    "crsr.execute(sql_statement)\n",
    "sql_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
